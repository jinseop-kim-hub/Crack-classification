{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from shutil import copy2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from typing import *\n",
    "from IPython.display import Image as IPImage\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import os\n",
    "from PIL import Image as Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import ConcatDataset\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "import timm  # PyTorch Image Models 라이브러리 설치 필요: pip install timm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 분류 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# from shutil import copy2\n",
    "\n",
    "def classify_and_modify(json_dir, image_dir, output_dir):\n",
    "    \"\"\"\n",
    "    JSON 데이터를 기반으로 이미지를 분류하고, 수정된 JSON 데이터를 저장합니다.\n",
    "\n",
    "    Args:\n",
    "        json_dir (str): JSON 파일이 저장된 디렉토리 경로.\n",
    "        image_dir (str): 이미지 파일이 저장된 디렉토리 경로.\n",
    "        output_dir (str): 결과 데이터를 저장할 디렉토리 경로.\n",
    "    \"\"\"\n",
    "    # 분류된 이미지와 수정된 JSON 파일을 저장할 디렉토리 설정\n",
    "    data_image_dir = os.path.join(output_dir, \"Data_image\")\n",
    "    data_label_dir = os.path.join(output_dir, \"Data_label\")\n",
    "    os.makedirs(data_image_dir, exist_ok=True)  # 이미지 저장 폴더 생성\n",
    "    os.makedirs(data_label_dir, exist_ok=True)  # JSON 저장 폴더 생성\n",
    "\n",
    "    # JSON 디렉토리 내 파일 탐색\n",
    "    for root, _, files in os.walk(json_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):  # JSON 파일만 처리\n",
    "                json_path = os.path.join(root, file)  # JSON 파일의 전체 경로 생성\n",
    "                # print(f\"Processing JSON file: {json_path}\")  # 실행 여부 확인용 로그\n",
    "\n",
    "                # JSON 파일 읽기 (UTF-8 인코딩)\n",
    "                with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                # JSON에서 이미지 파일 이름과 object_included 값을 추출\n",
    "                image_name = data[\"image\"][\"name\"]\n",
    "                object_included = data[\"image\"][\"object_included\"]\n",
    "                # print(f\"Image name: {image_name}, Object included: {object_included}\")  # 실행 여부 확인용 로그\n",
    "\n",
    "                # object_included 값에 따라 카테고리 분류\n",
    "                category = \"with_crack\" if object_included == \"Y\" else \"no_crack\"\n",
    "                category_dir = os.path.join(data_image_dir, category)\n",
    "                os.makedirs(category_dir, exist_ok=True)  # 카테고리 폴더 생성\n",
    "\n",
    "                # 하위 폴더 탐색 함수\n",
    "                def find_image_in_subfolders(image_dir, image_name):\n",
    "                    for root, _, files in os.walk(image_dir):\n",
    "                        if image_name in files:\n",
    "                            return os.path.join(root, image_name)\n",
    "                    return None\n",
    "\n",
    "                # 이미지 파일 복사\n",
    "                image_path = find_image_in_subfolders(image_dir, image_name) # 이미지 경로 생성\n",
    "                if image_path:  # 이미지 파일이 존재하는 경우\n",
    "                    copy2(image_path, category_dir)  # 이미지를 해당 카테고리 폴더로 복사\n",
    "                    # print(f\"Copied image to {category_dir}\")  # 실행 여부 확인용 로그\n",
    "                else:\n",
    "                    # 이미지 파일이 존재하지 않을 경우 경로 출력\n",
    "                    print(f\"실패 이미지 없음: {image_path}\")  # 오류 확인용 로그\n",
    "\n",
    "                # 수정된 JSON 데이터 생성\n",
    "                modified_data = {\n",
    "                    \"image\": {\n",
    "                        \"name\": data[\"image\"].get(\"name\", \"\"),  # \"name\" 값을 포함\n",
    "                        \"object_included\": object_included,  # \"object_included\" 값 포함\n",
    "                        \"labels\": []  # \"labels\" 초기화\n",
    "                    }\n",
    "                }\n",
    "                # \"annotations\" 리스트 처리\n",
    "                for annotation in data[\"image\"].get(\"annotations\", []):\n",
    "                    if annotation[\"labelNum\"] == 0:  # \"labelNum\" 값이 0인 경우만 처리\n",
    "                        modified_data[\"image\"][\"labels\"].append({\n",
    "                            \"label\": annotation[\"label\"],  # \"label\" 값 추가\n",
    "                            \"points\": annotation[\"points\"]  # \"points\" 값 추가\n",
    "                        })\n",
    "\n",
    "                # 수정된 JSON 데이터를 저장할 경로 설정\n",
    "                modified_json_path = os.path.join(data_label_dir, file)\n",
    "                with open(modified_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(modified_data, f, indent=4, ensure_ascii=False)  # 수정된 JSON 저장\n",
    "                    print(f\"Saved modified JSON to {modified_json_path}\")  # 저장 완료 로그\n",
    "\n",
    "# 코드 실행을 위한 입력 경로와 출력 경로 설정\n",
    "json_dir = r\"E:\\Desktop\\Data_preprocessing\\Label\"  # JSON 파일 경로\n",
    "image_dir = r\"E:\\Desktop\\Data_preprocessing\\Data\"  # 이미지 파일 경로\n",
    "output_dir = r\"E:\\Desktop\\Data_preprocessing\"  # 결과 데이터 저장 경로\n",
    "\n",
    "# 함수 호출\n",
    "classify_and_modify(json_dir, image_dir, output_dir)\n",
    "\n",
    "# 디렉토리 내용 확인\n",
    "print(f\"JSON directory contents: {os.listdir(json_dir)}\")  # JSON 파일 디렉토리 내용 출력\n",
    "print(f\"Image directory contents: {os.listdir(image_dir)}\")  # 이미지 파일 디렉토리 내용 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 Crop 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import json\n",
    "# import numpy as np\n",
    "\n",
    "# 원본 이미지가 있는 폴더 경로\n",
    "with_crack_dir = r'E:\\Desktop\\Data_preprocessing\\Data_image\\with_crack'\n",
    "\n",
    "# 크롭된 이미지를 저장할 폴더 경로\n",
    "with_crack_crop_dir = r'E:\\Desktop\\Data_preprocessing\\Data_image\\with_crack_crop'\n",
    "\n",
    "# JSON 파일들이 위치한 폴더 경로\n",
    "json_folder = r'E:\\Desktop\\Data_preprocessing\\Data_label'\n",
    "\n",
    "# 크롭된 이미지를 저장할 폴더 생성 (폴더가 없으면 생성)\n",
    "os.makedirs(with_crack_crop_dir, exist_ok=True)\n",
    "\n",
    "# JSON 폴더에서 모든 JSON 파일을 읽음\n",
    "json_files = [f for f in os.listdir(json_folder) if f.endswith('.json')]\n",
    "\n",
    "# 모든 JSON 파일 처리\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(json_folder, json_file)  # JSON 파일의 전체 경로\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(json_path, 'r') as f:\n",
    "        points_data = json.load(f)  # JSON 데이터 읽기\n",
    "\n",
    "    # 이미지 이름 가져오기\n",
    "    image_name = points_data[\"image\"].get(\"name\", None)  # \"image\" 섹션에서 \"name\" 값 읽기\n",
    "    if image_name is None:\n",
    "        print(f\"JSON 파일에 이미지 이름이 없습니다: {json_file}\")\n",
    "        continue\n",
    "\n",
    "    # 이미지 경로 생성\n",
    "    image_path = os.path.join(with_crack_dir, image_name)\n",
    "    print(f\"처리 중인 이미지 경로: {image_path}\")  # 경로 출력\n",
    "\n",
    "    # 이미지 읽기\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"이미지를 불러오지 못했습니다: {image_name}\")\n",
    "        continue\n",
    "\n",
    "     # JSON에서 \"labels\" 필드 처리\n",
    "    labels = points_data[\"image\"].get(\"labels\", [])\n",
    "    for label in labels:\n",
    "        points = label.get(\"points\", [])\n",
    "        if not points:\n",
    "            print(f\"Label에 points 데이터가 없습니다: {label}\")\n",
    "            continue\n",
    "        # 중심점 계산\n",
    "        points = np.array(points)  # 포인트 데이터를 numpy 배열로 변환\n",
    "        center_x, center_y = points.mean(axis=0).astype(int)  # 포인트의 평균값으로 중심점 계산\n",
    "\n",
    "        # 크롭 영역 계산\n",
    "        crop_size = 640  # 크롭할 이미지 크기 (640x640)\n",
    "        half_size = crop_size // 2  # 크롭 크기의 절반값\n",
    "        x_start = max(center_x - half_size, 0)  # 크롭 시작 x 좌표 (0 이하로 내려가지 않음)\n",
    "        y_start = max(center_y - half_size, 0)  # 크롭 시작 y 좌표 (0 이하로 내려가지 않음)\n",
    "        x_end = x_start + crop_size  # 크롭 끝 x 좌표\n",
    "        y_end = y_start + crop_size  # 크롭 끝 y 좌표\n",
    "\n",
    "        # 이미지 경계를 초과하지 않도록 좌표를 조정\n",
    "        x_start = max(0, min(x_start, image.shape[1] - crop_size))  # x 좌표 조정\n",
    "        y_start = max(0, min(y_start, image.shape[0] - crop_size))  # y 좌표 조정\n",
    "        x_end = x_start + crop_size  # 조정된 끝 x 좌표\n",
    "        y_end = y_start + crop_size  # 조정된 끝 y 좌표\n",
    "        \n",
    "        print(f\"크롭 좌표: x_start={x_start}, y_start={y_start}, x_end={x_end}, y_end={y_end}\")\n",
    "\n",
    "        # 이미지 크롭\n",
    "        cropped_image = image[y_start:y_end, x_start:x_end]  # 이미지 배열에서 크롭 영역 추출\n",
    "\n",
    "        # 크롭된 이미지 저장\n",
    "        crop_file_name = f\"{os.path.splitext(image_name)[0]}_crop_{label['label']}.jpg\"\n",
    "        save_path = os.path.join(with_crack_crop_dir, image_name)\n",
    "        cv2.imwrite(save_path, cropped_image)  # 크롭된 이미지를 저장\n",
    "        print(f\"{crop_file_name} 크롭 완료 및 저장: {save_path}\")  # 처리 완료 메시지 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json 데이터 내용을 수정 및 Data set 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import cv2\n",
    "# import pandas as pd\n",
    "\n",
    "# 이미지 데이터와 라벨 JSON 파일 경로\n",
    "image_dir = r\"E:\\Desktop\\Data_preprocessing\\Data_image\\with_crack_crop\"\n",
    "label_dir = r\"E:\\Desktop\\Data_preprocessing\\Data_label\"\n",
    "\n",
    "# 결과 저장 경로\n",
    "output_csv_path = r\"E:\\Desktop\\Data_preprocessing\\dataset.csv\"\n",
    "\n",
    "# JSON 폴더에서 모든 JSON 파일을 읽음\n",
    "json_files = [f for f in os.listdir(label_dir) if f.endswith('.json')]\n",
    "\n",
    "# 데이터셋을 저장할 리스트\n",
    "dataset = []\n",
    "\n",
    "# 모든 JSON 파일 처리\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(label_dir, json_file)  # JSON 파일의 전체 경로\n",
    "\n",
    "    # JSON 파일 읽기\n",
    "    with open(json_path, 'r') as f:\n",
    "        label_data = json.load(f)  # JSON에서 데이터 읽기\n",
    "\n",
    "    # 이미지 이름 가져오기\n",
    "    image_name = label_data[\"image\"].get(\"name\", None)\n",
    "    if image_name is None:\n",
    "        print(f\"JSON 파일에 이미지 이름이 없습니다: {json_file}\")\n",
    "        continue\n",
    "\n",
    "    # 이미지 경로 생성\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"이미지 파일이 없습니다: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    # 라벨 값 가져오기\n",
    "    labels = label_data[\"image\"].get(\"labels\", [])\n",
    "    for label in labels:\n",
    "        label_value = label.get(\"label\", None)\n",
    "        if label_value is None:\n",
    "            print(f\"Label 데이터가 없습니다: {label}\")\n",
    "            continue\n",
    "\n",
    "        # 데이터셋에 추가\n",
    "        dataset.append({\n",
    "            \"image_path\": image_path,\n",
    "            \"label\": label_value\n",
    "        })\n",
    "\n",
    "# 데이터셋을 Pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# 데이터셋을 CSV 파일로 저장\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"데이터셋 생성 완료: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = df.sample(10)\n",
    "\n",
    "# 이미지 경로와 라벨 추출\n",
    "image_paths = sampled_data['image_path'].tolist()\n",
    "labels = sampled_data['label'].tolist()\n",
    "\n",
    "# 이미지를 열고 플롯 준비\n",
    "images = [Image.open(img_path) for img_path in image_paths]\n",
    "\n",
    "# 플롯 설정\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))  # 2x5 격자\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 각 격자에 이미지와 라벨 표시\n",
    "for img, label, ax in zip(images, labels, axes):\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(label, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 불균형 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # CSV 데이터 읽기\n",
    "# df = pd.read_csv(csv_path)\n",
    "\n",
    "# 라벨별 개수 계산\n",
    "label_counts = df['label'].value_counts()\n",
    "\n",
    "# 막대그래프 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "label_counts.sort_index().plot(kind='bar')  # 라벨 순서대로 정렬하여 막대그래프 생성\n",
    "plt.title(\"Number of Images per Label\", fontsize=16)\n",
    "plt.xlabel(\"Label\", fontsize=14)\n",
    "plt.ylabel(\"Number of Images\", fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 감소 \n",
    "image_crack = df[(df['label']==0)]\n",
    "image_crack_reduce = image_crack.sample(frac=0.4,random_state=50)\n",
    "image_other = df[(df['label']!=0)]\n",
    "image_reduce = pd.concat([image_crack_reduce,image_other])\n",
    "df_reduce = image_reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset csv image_path경로 , label 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'E:\\Desktop\\Data_preprocessing\\dataset.csv'\n",
    "df =  pd.read_csv(csv_path)\n",
    "\n",
    "# dataset csv 경로 변경\n",
    "# df['image_path'] = df['image_path'].apply(lambda x:os.path.join('/content/Data_image/with_crack_crop',x.split('\\\\')[-1]))\n",
    "\n",
    "# 라벨 값 맵핑\n",
    "\n",
    "# 1.라벨 고유값 확인\n",
    "print(df['label'].unique())\n",
    "\n",
    "# 2.라벨 값을 숫자로 변환하기 위해 매핑 생성\n",
    "label_to_number = {label: idx for idx, label in enumerate(df['label'].unique())}\n",
    "print(\"\\n라벨 매핑:\")\n",
    "print(label_to_number)\n",
    "\n",
    "# 3.숫자로 변환\n",
    "df['label'] = df['label'].map(label_to_number)\n",
    "\n",
    "# 4.변환된 데이터 확인\n",
    "print(\"\\n숫자로 변환된 데이터:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 : Crack (균열)\n",
    "1 : Reticular Crack (망상 균열)\n",
    "2 : Spalling (스폴링)\n",
    "3 : Detachment (박리)\n",
    "4 : Material Separation (재료 분리)\n",
    "5 : Exhilaration (팽창)\n",
    "6 : Damage (손상)\n",
    "7 : Rebar (철근)\n",
    "8 : Efflorescence (백태)\n",
    "9 : Leak (누수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train / Valid 데이터 셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(\n",
    "     df, test_size=0.2,\n",
    "     random_state=0,\n",
    "     shuffle=True,\n",
    "     stratify=df[\"label\"],\n",
    ")\n",
    "\n",
    "# Reduced data set\n",
    "\n",
    "# train_df, valid_df = train_test_split(\n",
    "#     df_reduce,\n",
    "#     test_size=0.2,\n",
    "#     random_state=0,\n",
    "#     shuffle=True,\n",
    "#     stratify=df_reduce[\"label\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet, DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 사용자 정의 데이터셋 클래스 생성 (CustomDataset)\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        # 데이터셋 초기화\n",
    "        # dataframe: 이미지 경로와 레이블이 포함된 데이터프레임\n",
    "        # transform: 이미지에 적용할 전처리(transform) 함수\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 총 샘플 수 반환\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 주어진 인덱스(idx)에 해당하는 샘플을 반환\n",
    "        # 이미지 경로를 데이터프레임에서 가져옴\n",
    "        image_path = self.dataframe.iloc[idx]['image_path']\n",
    "        # 레이블 정보를 정수형으로 가져옴\n",
    "        label = int(self.dataframe.iloc[idx, 1])\n",
    "\n",
    "        # 이미지 파일을 열고 RGB 모드로 변환\n",
    "        img = Image.open(image_path).convert(\"RGB\")  # 이미지를 RGB로 로드\n",
    "\n",
    "\n",
    "        # transform이 지정되어 있다면 이미지에 전처리를 적용\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # 이미지와 레이블을 반환\n",
    "        return img, label\n",
    "    \n",
    "\n",
    "# Dataset 및 DataLoader 생성\n",
    "train_dataset = CustomDataset(train_df, transform=train_transform)\n",
    "valid_dataset = CustomDataset(valid_df, transform=valid_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AugmentedDataset 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 레이블을 가진 데이터만 포함하는 AugmentedDataset 클래스 생성\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        # 데이터프레임에서 특정 레이블(5, 6, 7, 8)만 필터링하여 데이터셋 생성\n",
    "        self.dataframe = dataframe[dataframe['label'].isin([5, 6, 7, 8])]\n",
    "        self.transform = transform\n",
    "        self.repeat = 5 # aug 증가량 조절절\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 총 샘플 수 반환\n",
    "        return len(self.dataframe) * self.repeat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "          # 반복된 데이터셋 인덱스를 원본 인덱스로 변환\n",
    "        original_idx = idx % len(self.dataframe)\n",
    "        \n",
    "        # 주어진 인덱스(idx)에 해당하는 샘플을 반환\n",
    "        # 이미지 경로를 데이터프레임에서 가져옴\n",
    "        img_name = self.dataframe.iloc[original_idx]['image_path']\n",
    "        # 이미지 파일을 열고 RGB 모드로 변환\n",
    "        img = Image.open(img_name).convert('RGB')\n",
    "        # 레이블 정보를 정수형으로 가져옴\n",
    "        label = int(self.dataframe.iloc[original_idx]['label'])\n",
    "\n",
    "        # transform이 지정되어 있다면 이미지에 전처리를 적용\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # 이미지와 레이블을 반환\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리 파이프라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 파이프라인 정의\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 이미지 크기 조정\n",
    "    transforms.ToTensor(),  # 텐서로 변환 및 자동으로 픽셀 값 /255 정규화\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 이미지넷 기준\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터 증강을 위한 transform 정의\n",
    "augment_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 이미지를 224x224로 리사이즈\n",
    "    transforms.RandomRotation(90),  # 이미지를 -90도에서 90도 사이로 랜덤 회전\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # 이미지 반전\n",
    "    transforms.ToTensor(),  # 이미지를 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 이미지넷 기준\n",
    "                        std=[0.229, 0.224, 0.225]),  # 채널별 평균과 표준편차로 정규화\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 검증 데이터 크기 조정\n",
    "    transforms.ToTensor(),  # 텐서로 변환 및 자동 /255 정규화\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset 및 DataLoader 생성\n",
    "#train set\n",
    "    # CustomDataset 인스턴스 생성 (기본 학습 데이터셋)\n",
    "train_dataset = CustomDataset(train_df, transform=train_transform)\n",
    "    # AugmentedDataset 인스턴스 생성 (증강된 학습 데이터셋)\n",
    "augmented_dataset = AugmentedDataset(train_df, transform=augment_transform)\n",
    "    # 기본 학습 데이터셋과 증강된 데이터셋을 결합하여 하나의 데이터셋으로 생성\n",
    "combined_train_dataset = ConcatDataset([train_dataset, augmented_dataset])\n",
    "\n",
    "#Valid set\n",
    "valid_dataset = CustomDataset(valid_df, transform=valid_transform)\n",
    "\n",
    "#Loader\n",
    "train_loader = DataLoader(combined_train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Convolutional Block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Convolutional Block 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 256)  # Input size depends on the input image dimensions\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional Blocks\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = torch.flatten(x, 1)  # Flatten all dimensions except batch\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 ResNet18 모델 불러오기\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# 모델의 마지막 완전 연결 계층(fc)을 사용자 정의 계층으로 대체\n",
    "# 이 계층은 in_features에서 10개의 출력으로 매핑합니다 (10개 클래스 분류를 위함)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 10),\n",
    ")\n",
    "\n",
    "# 교차 엔트로피 손실 함수 초기화\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 최적화 알고리즘으로 Adam 사용\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "\n",
    "# 베스트 가중치 로드 \n",
    "# model.load_state_dict(torch.load('/content/best_model_before(res).pth'))  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 Xception 모델 불러오기\n",
    "model = timm.create_model('xception', pretrained=True)\n",
    "\n",
    "# 모델의 마지막 계층 수정 (출력 클래스 수에 맞게 조정)\n",
    "model.fc = nn.Linear(\n",
    "    model.num_features, 10)  # 10개의 클래스 분류\n",
    "\n",
    "# 교차 엔트로피 손실 함수 초기화\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화 알고리즘으로 Adam 사용\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "\n",
    "# GPU 또는 CPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 파라미터 설정\n",
    "num_epochs =50   # 학습 반복 횟수\n",
    "best_val_acc = 0.0  # 최상의 검증 정확도를 저장하는 변수\n",
    "patience = 5  # 얼리 스탑핑을 위한 patience 설정 (개선되지 않은 횟수)\n",
    "no_improve = 0  # 개선되지 않은 에포크 수를 카운트하는 변수\n",
    "\n",
    "# 훈련 및 검증 손실을 추적하기 위한 리스트\n",
    "train_acces = []\n",
    "valid_acces = []\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # 모델을 학습 모드로 전환\n",
    "    model.train()\n",
    "    running_loss = 0.0  # 에포크 동안의 총 손실을 저장하는 변수\n",
    "    correct_train = 0  # 정확하게 예측한 학습 데이터의 개수를 저장하는 변수\n",
    "    total_train = 0  # 총 학습 데이터 개수를 저장하는 변수\n",
    "\n",
    "    # 학습 데이터를 반복하여 모델 업데이트\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", dynamic_ncols=True):\n",
    "        # 데이터를 장치로 이동 (GPU 또는 CPU)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 옵티마이저의 기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 모델에 입력을 전달하여 예측값 출력\n",
    "        outputs = model(inputs)\n",
    "        # 손실 함수 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 손실에 대한 역전파 수행 (기울기 계산)\n",
    "        loss.backward()\n",
    "        # 옵티마이저를 통해 모델 파라미터 업데이\n",
    "        optimizer.step()\n",
    "        # 현재 배치의 손실을 누적\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산을 위한 예측값 처리\n",
    "        _, predicted = torch.max(outputs.data, 1) # 최대값을 가지는 클래스 예측\n",
    "        total_train += labels.size(0) # 총 학습 데이터 수 누적\n",
    "        correct_train += (predicted == labels).sum().item() # 맞춘 예측의 개수 누적\n",
    "\n",
    "    # 에포크별 학습 정확도와 손실 계산\n",
    "    train_acc = correct_train / total_train\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validate\n",
    "    model.eval()  # 모델을 평가 모드로 전환 (드롭아웃, 배치 정규화 등 비활성화)\n",
    "    running_val_loss = 0.0  # 검증 손실을 저장하는 변수\n",
    "    correct_val = 0  # 정확하게 예측한 검증 데이터의 개수를 저장하는 변수\n",
    "    total_val = 0  # 총 검증 데이터 개수를 저장하는 변수\n",
    "    with torch.no_grad(): # 검증 시에는 기울기를 계산하지 않음 (메모리 및 계산량 절약)\n",
    "        for inputs, labels in valid_loader:\n",
    "            # 데이터를 장치로 이동\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # 모델에 입력을 전달하여 예측값 출력\n",
    "            outputs = model(inputs)\n",
    "            # 손실 함수 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            # 현재 배치의 손실을 누적\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산을 위한 예측값 처리\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 최대값을 가지는 클래스 예측\n",
    "            total_val += labels.size(0)  # 총 검증 데이터 수 누적\n",
    "            correct_val += (predicted == labels).sum().item()  # 맞춘 예측의 개수 누적\n",
    "\n",
    "    # 에포크별 검증 정확도와 손실 계산\n",
    "    val_acc = correct_val / total_val  # 검증 정확도 계산\n",
    "    val_loss = running_val_loss / len(valid_loader)  # 검증 손실 평균 계산\n",
    "    \n",
    "    # 정확도 & 손실 기록\n",
    "    train_acces.append(train_acc)\n",
    "    valid_acces.append(val_acc)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(val_loss)\n",
    "\n",
    "    # 학습 및 검증 결과 출력\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, '\n",
    "          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')\n",
    "\n",
    "     # 최상의 검증 정확도를 기록하고 모델 저장\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        save_dir = 'E:\\Desktop\\Data_preprocessing\\BEST_model'\n",
    "        os.makedirs(save_dir, exist_ok=True)  # 경로가 없으면 생성\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, 'best_model_before.pth'))\n",
    "        no_improve = 0\n",
    "        print(f\"Epoch {epoch+1}: val_acc={val_acc:.4f}, best_val_acc={best_val_acc:.4f}\")\n",
    "\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:  # 설정한 얼리 스타핑 patience에 도달하면 학습을 중단합니다.\n",
    "            print(f\"Epoch {epoch+1}: no_improve={no_improve}, patience={patience}\")\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 그리기\n",
    "actual_epochs = len(train_losses)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,8))\n",
    "\n",
    "#Loss 그래프\n",
    "axes[0].plot(range(1, actual_epochs + 1), train_losses, label='Train Loss', color='blue') # Train Loss 그래프\n",
    "axes[0].plot(range(1, actual_epochs + 1), valid_losses, label='Validation Loss', color='orange') # Validation Loss 그래프\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "#acc 그래프\n",
    "axes[1].plot(range(1, actual_epochs + 1), train_acces, label='Train Accuracy', color='blue') # Train Accuracy 그래프\n",
    "axes[1].plot(range(1, actual_epochs + 1), valid_acces, label='Validation Accuracy', color='orange') # Validation Accuracy 그래프\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "# 그래프 출력\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 혼동 행렬로 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in valid_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_predictions.append(predicted.cpu().numpy())\n",
    "\n",
    "all_labels = np.concatenate(all_labels)\n",
    "all_predictions = np.concatenate(all_predictions)\n",
    "\n",
    "conf_mat = confusion_matrix(all_labels, all_predictions)\n",
    "conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "#그래프 출력\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(conf_mat_normalized, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## best model load & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/content/best_model_before.pth'))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
